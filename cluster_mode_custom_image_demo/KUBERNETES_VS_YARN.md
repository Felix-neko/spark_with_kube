# Почему нельзя передать файл напрямую в Kubernetes (как в YARN)

## Фундаментальная разница

### YARN (работает с локальными файлами)
```python
# В YARN это работает:
spark-submit \
    --master yarn \
    --deploy-mode cluster \
    cluster_entrypoint.py  # ← Просто имя файла
```

**Почему работает:**
- YARN имеет встроенный механизм распределения файлов
- Файлы автоматически копируются на узлы кластера через HDFS или локальную файловую систему
- `spark-submit` сам загружает файл в YARN Application Master
- Application Master имеет доступ к распределённой файловой системе кластера

### Kubernetes (НЕ работает с локальными файлами)
```python
# В Kubernetes это НЕ работает:
spark-submit \
    --master k8s://https://... \
    --deploy-mode cluster \
    /home/felix/.../app.py  # ← Локальный путь
```

**Почему НЕ работает:**
- Kubernetes использует изолированные контейнеры
- Контейнер драйвера запускается в отдельном поде
- Локальные файлы с вашей машины **недоступны** внутри контейнера
- Нет встроенного механизма распределения файлов (как HDFS в YARN)

## Что происходит при попытке использовать локальный путь

1. Вы запускаете `spark-submit` с локальным путём `/home/felix/.../app.py`
2. Spark создаёт под драйвера в Kubernetes
3. Spark пытается скопировать файл в `/tmp/spark-upload-...` **внутри контейнера**
4. **ОШИБКА:** Файл находится на вашей машине, а не в контейнере
5. Результат: `FileNotFoundError: /tmp/spark-upload-.../app.py`

## Доступные решения для Kubernetes

### ✅ Вариант 1: HTTP/HTTPS URL (используется в run_in_cluster_mode.py)

**Как работает:**
1. Запускается HTTP-сервер на хост-машине: `python -m http.server 8765`
2. Сервер раздаёт файлы из директории с `app.py`
3. В `spark-submit` передаётся URL: `http://172.19.0.1:8765/app.py`
4. Контейнер драйвера скачивает файл по HTTP

**Преимущества:**
- Работает без модификации Docker-образа
- Простая настройка
- Аналог YARN-подхода (файл передаётся извне)

**Недостатки:**
- Требуется запущенный HTTP-сервер
- Файл должен быть доступен по сети

### ❌ Вариант 2: Локальный путь

**НЕ РАБОТАЕТ** - файл недоступен в контейнере.

### ❌ Вариант 3: ConfigMap

**Попытка:**
```python
--conf spark.kubernetes.driver.volumes.configMap.my-app.mount.path=/app
```

**Результат:**
```
IllegalArgumentException: Kubernetes Volume type 'configMap' is not supported
```

**Почему не работает:**
- Spark 3.5.8 не поддерживает ConfigMap volumes через конфигурацию
- Требуется модификация кода Spark или использование Spark Operator

### ✅ Вариант 4: Встроить в Docker-образ

**Как работает:**
```dockerfile
FROM felixneko/spark:spark-3.5.8-python-3.8
COPY app.py /opt/spark/work-dir/app.py
```

```python
spark-submit \
    --conf spark.kubernetes.container.image=my-custom-image \
    local:///opt/spark/work-dir/app.py
```

**Преимущества:**
- Файл гарантированно доступен в контейнере
- Не требуется HTTP-сервер

**Недостатки:**
- Требуется пересборка образа при каждом изменении `app.py`
- **Запрещено пользователем** (один образ для многих приложений)

## Вывод

**Для Kubernetes cluster mode единственный практичный вариант без модификации образа - это HTTP/HTTPS URL.**

Это не ограничение или недостаток - это архитектурная особенность Kubernetes:
- Контейнеры изолированы
- Нет общей файловой системы (как HDFS в Hadoop)
- Файлы должны быть либо в образе, либо доступны по сети

HTTP-сервер в `run_in_cluster_mode.py` - это правильное и рекомендуемое решение для вашего случая.
